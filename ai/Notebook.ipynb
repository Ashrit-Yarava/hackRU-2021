{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files: 1000\n"
     ]
    }
   ],
   "source": [
    "food_product = 'tacos'\n",
    "filepath = Path('data/images') / Path(food_product)\n",
    "files = glob(str(filepath) + \"/*.jpg\")\n",
    "print(f\"Number of Files: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 323.85it/s]\n"
     ]
    }
   ],
   "source": [
    "resize_value = (128, 128)\n",
    "images = []\n",
    "\n",
    "for file in tqdm(files):\n",
    "    image = Image.open(file)\n",
    "    image = image.resize(resize_value)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    if(len(image.shape) != 3):\n",
    "        image = np.stacK((image, image, image), axis = 2)\n",
    "        images.append(image)\n",
    "    else:\n",
    "        images.append(image)\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('data/numpy') / Path(food_product + '.npy')\n",
    "np.save(str(save_path), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.dcgan import Generator, Discriminator, weights_init_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, idx): return torch.from_numpy(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"n_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr_g\": 0.001,\n",
    "    \"lr_d\": 0.0001,\n",
    "    \"b1\": 0.5,\n",
    "    \"b2\":0.999,\n",
    "    \"latent_dim\": 500,\n",
    "    \"img_size\": 128,\n",
    "    \"channels\": 3,\n",
    "    \"sample_interval\": 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('drive/MyDrive/Food Images - 128/tacos.npy')\n",
    "data = np.load()\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Define the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(Dataloader(images), batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "# Define the models.\n",
    "generator = Generator(opt)\n",
    "discriminator = Discriminator(opt)\n",
    "\n",
    "# Convert to CUDA if available\n",
    "if cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    adversarial_loss = loss.cuda()\n",
    "\n",
    "# Apply weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Initialize optimizers.\n",
    "opt_g = torch.optim.Adam(generator.parameters(), lr = opt['lr_g'], betas = (opt['b1'], opt['b2']))\n",
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr = opt['lr_d'], betas = (opt['b1'], opt['b2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt['n_epochs']):\n",
    "    for idx, images in enumerate(dataloader):\n",
    "\n",
    "        # Create the True/False Identifiers for Discriminator\n",
    "        valid = Variable(Tensor(images.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(images.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        real_imgs = Variable(images.type(Tensor)) / 127.5 - 0.5\n",
    "\n",
    "        opt_g.zero_grad()\n",
    "    \n",
    "        # Generate Images.\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (images.shape[0], opt['latent_dim']))))\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Train the Generator\n",
    "        g_loss = loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        opt_g.step()\n",
    "\n",
    "        # Train the Discriminator\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        opt_d.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d]\\t[Batch %d/%d]\\t[D loss: %f]\\t[G loss: %f]\"\n",
    "                % (epoch, opt['n_epochs'], idx, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "        if idx % 50 == 0:\n",
    "            z_temp = Tensor(np.random.normal(0, 1, (1, opt['latent_dim'])))\n",
    "            a = generator(z_temp).permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "            a = (a[0] / 2) + 0.5\n",
    "            plt.imshow(a, interpolation='nearest')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f8481c4bbda01924aa69a09474cad5e771241f2cfb11379a4da027ba4fefcd0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
